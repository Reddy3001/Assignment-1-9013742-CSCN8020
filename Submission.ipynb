{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07bab7af",
   "metadata": {},
   "source": [
    "# CSCN8020 – Assignment 1 \n",
    "\n",
    "**Course:** Reinforcement Learning Programming (CSCN8020)  \n",
    "**Student:** Jahnavi Pakanati\n",
    "**Student ID:** 9013742\n",
    "\n",
    "This notebook contains:\n",
    "- **Problem 1**: MDP design for a pick-and-place robot  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd4aee",
   "metadata": {},
   "source": [
    "## Problem 1 – Pick-and-Place Robot (MDP Design)\n",
    "\n",
    "We model the **pick-and-place** task as a **Markov Decision Process (MDP)**.\n",
    "\n",
    "#### 1) States (S)\n",
    "A state should capture the **minimum information** needed to choose good actions:\n",
    "- Robot arm pose (discretized or continuous), e.g., `(x, y, z)` or `(joint1, joint2, joint3, ...)`\n",
    "- Gripper: `open` / `closed`\n",
    "- Object status: `on_table` / `in_gripper` / `at_target`\n",
    "- (Optional) Velocities for smoothness: `vx, vy, vz`\n",
    "\n",
    "##### 2) Actions (A)\n",
    "Primitive, low-level actions that the policy can choose:\n",
    "- Arm motion: `move_up`, `move_down`, `move_left`, `move_right` (optionally `move_forward`, `move_backward`)\n",
    "- Gripper: `open_gripper`, `close_gripper`\n",
    "\n",
    "##### 3) Rewards (R)\n",
    "Shape the behavior to be **fast** and **smooth**:\n",
    "- `+10` when the object is placed at the target location (`at_target`)\n",
    "- `-1` per time step to discourage unnecessary movement\n",
    "- `-5` penalty for dropping the object or collisions\n",
    "\n",
    "> ***Reasoning:*** This reward encourages successful completion, penalizes wasted motion, and discourages unsafe behaviors. The state and action choices reflect the ***control levers*** the agent has and the **task status** it must track.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
